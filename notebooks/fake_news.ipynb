{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake news detekcija\n",
    "\n",
    "### Importovanje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\krick\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras import Sequential\n",
    "from keras.layers import SpatialDropout1D, Embedding, LSTM, Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib as plt\n",
    "\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ucitavanje i spajanje csv fajlova sa dodatim FAKE atributom da se razlikuje izvor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 44898 entries, 0 to 23480\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   title    44898 non-null  object\n",
      " 1   text     44898 non-null  object\n",
      " 2   subject  44898 non-null  object\n",
      " 3   date     44898 non-null  object\n",
      " 4   fake     44898 non-null  bool  \n",
      "dtypes: bool(1), object(4)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "true_df = pd.read_csv('../datasets/fake-news/True.csv')\n",
    "fake_df = pd.read_csv('../datasets/fake-news/Fake.csv')\n",
    "\n",
    "true_df = true_df.assign(fake = [False for _ in true_df.iterrows()])\n",
    "fake_df = fake_df.assign(fake = [True for _ in fake_df.iterrows()])\n",
    "\n",
    "df = pd.concat([true_df, fake_df])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provera koliko postoji null vrednosti <b>subject</b>\n",
    "#### Bitno nam je da se broj mali, jer ce igrati ulogu u daljoj klasifikaciji!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title      0\n",
      "text       0\n",
      "subject    0\n",
      "date       0\n",
      "fake       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obrada teksta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Koliko je prljav tekst?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_plot(index):\n",
    "    example = df[df.index == index][['text', 'fake']].values[0]\n",
    "    if len(example) > 0:\n",
    "        print(example[0])\n",
    "        print('Fake:', example[1])\n",
    "\n",
    "def print_cell():\n",
    "    index = random.randint(0, df.shape[0])\n",
    "    print_plot(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOHANNESBURG (Reuters) - South Africa s government is considering a range of budget cuts that could include slashing social grants for the most vulnerable in order to pay for free tertiary education, a newspaper reported on Friday. South Africa s rand weakened on Thursday after comments by President Jacob Zuma raised concerns about higher spending on education, which would put added strain on the country s already stretched public finances.  The Mail & Guardian newspaper said a presidential fiscal committee had presented a document to Zuma outlining possible cuts to fund free higher education for lower-income students as well as plugging a swelling budget deficit.  Options included cuts to the social grants that are the main source of income for around 17 million people - a third of the population - and slashing the budgets for housing, infrastructure and the armed forces. A freeze on civil servant wage hikes was also on the cards, the newspaper reported. The Presidency and Treasury did not immediately respond to requests for comment. Violent protests by students and activists demanding free tuition rocked several South African universities last year, underlying tensions in a country marred by glaring income disparities defined largely by race. South Africa is staring down the barrel of ratings downgrades after the Treasury last month widened the 2017/18 budget deficit estimate to 4.3 percent of gross domestic product while lowering this year s economic growth forecast to 0.7 percent from 1.3 percent. \n",
      "Fake: False\n"
     ]
    }
   ],
   "source": [
    "def safe_print_cell():\n",
    "    try:\n",
    "        print_cell()\n",
    "    except IndexError:\n",
    "        print_cell()\n",
    "\n",
    "safe_print_cell()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tekst je relativno prljav. Konkretno, sadrzi karaktere poput [], () i sl.\n",
    "1. Konvertujemo tekstove u lower case\n",
    "2. Ukljanjamo stop reci\n",
    "3. Izbacujemo numericke oznake iz teksta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "    BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "    STOPWORDS = set(stopwords)\n",
    "    text = text.lower()\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text)\n",
    "    text = BAD_SYMBOLS_RE.sub('', text)\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cistimo tekst svih clanaka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krick\\anaconda3\\envs\\nm\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df['text'] = df['text'].apply(clean_text)\n",
    "df['text'] = df['text'].str.replace('\\d+', '')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Provera nove verzije teksta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brussels reuters israel must halt new building plans settler homes west bank european union foreign service said statement wednesday warning settlements threatened future peace deal palestinians european union requested clarifications israeli authorities conveyed expectation reconsider decisions detrimental ongoing efforts towards meaningful peace talks statement said settlement activity illegal international law undermines viability twostate solution prospect lasting peace eu maintains lands israel occupied since  middle east war including west bank east jerusalem golan heights part internationally recognized borders israel\n",
      "Fake: False\n"
     ]
    }
   ],
   "source": [
    "safe_print_cell()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inicijalna podesavanja parametara i tokenizacija tekstova clanaka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 209040 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "MAX_NB_WORDS = 50000\n",
    "MAX_SEQUENCE_LENGTH = 250\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(df['text'].values)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bitno je da svi inputi budu istih dimenzija, pa dodajemo padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (44898, 250)\n"
     ]
    }
   ],
   "source": [
    "X = tokenizer.texts_to_sequences(df['text'].values)\n",
    "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Konvertovanje bool oznaka u numericke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of label tensor: (44898, 2)\n"
     ]
    }
   ],
   "source": [
    "Y = pd.get_dummies(df['fake']).values\n",
    "print('Shape of label tensor:', Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35918, 250) (35918, 2)\n",
      "(8980, 250) (8980, 2)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20, random_state = 42)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kreiranje modela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "506/506 [==============================] - 362s 710ms/step - loss: 0.1159 - accuracy: 0.9578 - val_loss: 0.0811 - val_accuracy: 0.9786\n",
      "Epoch 2/5\n",
      "506/506 [==============================] - 376s 743ms/step - loss: 0.0216 - accuracy: 0.9938 - val_loss: 0.1092 - val_accuracy: 0.9716\n",
      "Epoch 3/5\n",
      "506/506 [==============================] - 363s 718ms/step - loss: 0.0145 - accuracy: 0.9959 - val_loss: 0.0274 - val_accuracy: 0.9925\n",
      "Epoch 4/5\n",
      "506/506 [==============================] - 330s 653ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.0365 - val_accuracy: 0.9905\n",
      "Epoch 5/5\n",
      "506/506 [==============================] - 368s 727ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.0306 - val_accuracy: 0.9919\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 64\n",
    "\n",
    "history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluacija modela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 16s 57ms/step - loss: 0.0278 - accuracy: 0.9938\n",
      "Test set\n",
      "  Loss: 0.028\n",
      "  Accuracy: 0.994\n"
     ]
    }
   ],
   "source": [
    "accr = model.evaluate(X_test,Y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Serializacija modela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/fake_news\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000002293F724748> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "model.save('../models/fake_news')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testiranje na novom skupu podataka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2096 entries, 0 to 2095\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    2096 non-null   object\n",
      " 1   fake    2096 non-null   bool  \n",
      "dtypes: bool(1), object(1)\n",
      "memory usage: 18.5+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krick\\anaconda3\\envs\\nm\\lib\\site-packages\\ipykernel_launcher.py:17: FutureWarning: The default value of regex will change from True to False in a future version.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 78353 unique tokens.\n",
      "Shape of data tensor: (4146, 250)\n",
      "Shape of label tensor: (4146, 2)\n"
     ]
    }
   ],
   "source": [
    "new_df = pd.read_csv('../datasets/fake-news/news_articles.csv')\n",
    "new_df = new_df.assign(fake = [True for _ in new_df.iterrows()])\n",
    "new_df = new_df[['text', 'fake']]\n",
    "new_true = pd.read_csv('../datasets/fake-news/articles1.csv')\n",
    "new_true = new_true.head(len(new_df.index))\n",
    "new_true = new_true.assign(fake = [False for _ in new_df.iterrows()])\n",
    "new_true = new_true[['content', 'fake']]\n",
    "new_true.rename(columns = {'content':'text'}, inplace = True)\n",
    "new_true.info()\n",
    "\n",
    "new_df = pd.concat([new_df, new_true])\n",
    "new_df = new_df.dropna()\n",
    "\n",
    "new_df = new_df.reset_index(drop=True)\n",
    "\n",
    "new_df['text'] = new_df['text'].apply(clean_text)\n",
    "new_df['text'] = new_df['text'].str.replace('\\d+', '')\n",
    "\n",
    "tokenizer_new = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer_new.fit_on_texts(new_df['text'].values)\n",
    "new_word_index = tokenizer_new.word_index\n",
    "print('Found %s unique tokens.' % len(new_word_index))\n",
    "\n",
    "X_new = tokenizer_new.texts_to_sequences(new_df['text'].values)\n",
    "X_new = pad_sequences(X_new, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', X_new.shape)\n",
    "\n",
    "Y_new = pd.get_dummies(new_df['fake']).values\n",
    "print('Shape of label tensor:', Y_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "awards season leaders everyone already knew awards season leaders became ever apparent thursday directors guild america revealed nominees top prize damien chazelle la la land garth davis lion barry jenkins moonlight kenneth lonergan manchester sea denis villeneuve arrival real news came announcement nate parker received nomination outstanding achievement director signals redemption sorts mr parker whose awards hopes debut film birth nation torpedoed controversy emerged around rape charges faced acquitted nearly  years ago category nominations also went mr davis second one work lion kelly fremon craig edge seventeen dan trachtenberg  cloverfield lane tim miller whose satirical superhero film deadpool surprise presence years awards race main feature film category notable omissions mel gibson hacksaw ridge martin scorsese whose passion project silence received neither directors guild nomination one producers guild found room deadpool nominations list week taken films shutout screen actors guild award nominations mr scorsese silence guaranteed ignored best picture best director oscar races year academy award nominations announced jan  guild awards given far weight oscars race awards critics journalists represent industry sentiment huge number guild members also belong academy motion picture arts sciences dga award nominations capped busy week began golden globes included nomination announcements producers british academy film television arts also shares members american academy dealing #baftasowhite controversy picking slate lead acting directing nominees taken golden globes wins guild nominations make clear calcification years race around leading contenders la la land front ever\n",
      "Fake: False\n"
     ]
    }
   ],
   "source": [
    "def print_plot(index):\n",
    "    example = new_df[new_df.index == index][['text', 'fake']].values[0]\n",
    "    if len(example) > 0:\n",
    "        print(example[0])\n",
    "        print('Fake:', example[1])\n",
    "\n",
    "def print_cell():\n",
    "    index = random.randint(0, new_df.shape[0])\n",
    "    print_plot(index)\n",
    "\n",
    "print_cell()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluacija"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 16s 123ms/step - loss: 2.1467 - accuracy: 0.6568\n",
      "Validation set\n",
      "  Loss: 2.147\n",
      "  Accuracy: 0.657\n"
     ]
    }
   ],
   "source": [
    "accr_new = model.evaluate(X_new,Y_new)\n",
    "print('Validation set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr_new[0],accr_new[1]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "48776eafa8df7cd6de53d4da908f51dce28a667ead450d14c1aa6fb1367c4081"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
